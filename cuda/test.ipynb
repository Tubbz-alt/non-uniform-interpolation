{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using /tmp/torch_extensions as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /tmp/torch_extensions/gp_interp_cuda/build.ninja...\n",
      "Building extension module gp_interp_cuda...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module gp_interp_cuda...\n",
      "Num coords: 4\n",
      "Doing a forward pass...\n",
      "Doing a backward pass...\n",
      "Loss: 0.12815387547016144\n",
      "Success!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b900d5d2690>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "gp_interp_cuda = load('gp_interp_cuda', ['gp_interp_cuda.cpp', 'gp_interp_cuda_kernel.cu'], verbose=True)\n",
    "\n",
    "import sys; sys.path.extend(['.', '../cuda'])\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torchvision.transforms.functional as TVF\n",
    "\n",
    "from gp_interp import GPInterp\n",
    "\n",
    "device = 'cuda'\n",
    "# img_pil = Image.open('/tmp/skoroki/datasets/ffhq/thumbnails128x128/00000.png')\n",
    "# img_pil = Image.open('./water.jpg')\n",
    "# img = TVF.to_tensor(img_pil).to(device)\n",
    "size = 3\n",
    "img = torch.linspace(1, 0, size).view(-1, 1).repeat(1, size).unsqueeze(2).to(device).permute(2, 0, 1)\n",
    "torch.manual_seed(42)\n",
    "img = torch.rand_like(img.cpu()).to(img.device)\n",
    "gp = GPInterp(img.shape[1], img.shape[2], 0.8, 1.0, 1)\n",
    "# gp.means = nn.Parameter(torch.tensor([[1.0, 1.0]]))\n",
    "gp.to(device)\n",
    "\n",
    "print('Num coords:', len(gp.means))\n",
    "\n",
    "print('Doing a forward pass...')\n",
    "out = gp(img)\n",
    "\n",
    "print('Doing a backward pass...')\n",
    "loss = (out - img).abs().mean()\n",
    "loss.backward()\n",
    "print('Loss:', loss.item())\n",
    "print('Success!')\n",
    "\n",
    "# TVF.to_pil_image(out.cpu())\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[0].detach().cpu())\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(out[0].detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1840, -0.1927],\n",
       "        [ 0.0133,  0.0353],\n",
       "        [-0.0679, -0.0196],\n",
       "        [-0.0719, -0.1241]], device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gp.means.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e7d6e477b8a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "source": [
    "tqdm._instances.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# img_pil = Image.open('/tmp/skoroki/datasets/ffhq/thumbnails128x128/00000.png')\n",
    "img_pil = Image.open('./water.jpg')\n",
    "img = TVF.to_tensor(img_pil).to(device)\n",
    "gp = GPInterp(img.shape[1], img.shape[2], 0.2, 2.0, 5)\n",
    "gp.to(device)\n",
    "out = gp(img)\n",
    "\n",
    "\n",
    "img_np = np.array(TVF.to_pil_image(out.cpu()))\n",
    "\n",
    "# plt.imshow(img_np)\n",
    "# plt.scatter(gp.means.grid)\n",
    "# TVF.to_pil_image(out.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/5000 [00:00<01:08, 73.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 64/5000 [00:00<01:05, 75.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 112/5000 [00:01<01:10, 69.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 160/5000 [00:02<01:03, 75.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 172/5000 [00:02<01:05, 73.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-75d31ce4b786>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NaN grad!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# img_pil = Image.open('/tmp/skoroki/datasets/ffhq/thumbnails128x128/00000.png')\n",
    "img_pil = Image.open('./water.jpg')\n",
    "img = TVF.to_tensor(img_pil).to(device)\n",
    "gp = GPInterp(img.shape[1], img.shape[2], 0.2, 2.0, 5)\n",
    "gp.to(device)\n",
    "means_old = gp.means.data.cpu().tolist()\n",
    "optim = torch.optim.SGD(gp.parameters(), lr=10.0, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optim, step_size=500, gamma=0.333)\n",
    "# optim = torch.optim.Adam(gp.parameters(), lr=1000.0)\n",
    "grad_norms = []\n",
    "for i in tqdm(range(5000)):\n",
    "    out = gp(img)\n",
    "    loss = (out - img).pow(2).mean()\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    if np.isnan(gp.means.grad.max().item()):\n",
    "        print('NaN grad!')\n",
    "        break\n",
    "    #torch.nn.utils.clip_grad_norm_(gp.parameters(), 10.0)\n",
    "    if np.isnan(gp.means.grad.max().item()):\n",
    "        print('NaN grad after ...!')\n",
    "        break\n",
    "    grad_norms.append(gp.means.grad.norm().item())\n",
    "    optim.step()\n",
    "    if np.isnan(gp.means.max().item()):\n",
    "        print('NaN weight!')\n",
    "        break\n",
    "    scheduler.step()\n",
    "    gp.means.data[:,0].clamp_(0.0, img.shape[2])\n",
    "    gp.means.data[:,1].clamp_(0.0, img.shape[1])\n",
    "    if i % 50 == 0:\n",
    "        print(f'{loss.item():.05f}')\n",
    "        \n",
    "print('diff passed:', (torch.tensor(means_old).to(device) - gp.means).pow(2).mean())\n",
    "plt.plot(grad_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TVF.to_pil_image(GPInterp(img.shape[1], img.shape[2], 0.2, 1.0, 5).cuda()(img).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TVF.to_pil_image(out.cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
